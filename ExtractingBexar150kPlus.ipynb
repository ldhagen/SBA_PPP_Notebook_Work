{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a423672-0e7d-4205-abca-40f2bdb14390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import chardet\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Complete Bexar County ZIP codes\n",
    "bexar_zips = {\n",
    "    '78006', '78009', '78015', '78023', '78039', '78056', '78073', '78101', \n",
    "    '78108', '78109', '78112', '78114', '78121', '78124', '78154', '78161', \n",
    "    '78163', '78201', '78202', '78203', '78204', '78205', '78207', '78208', \n",
    "    '78209', '78210', '78211', '78212', '78213', '78214', '78215', '78216', \n",
    "    '78217', '78218', '78219', '78220', '78221', '78222', '78223', '78224', \n",
    "    '78225', '78226', '78227', '78228', '78229', '78230', '78231', '78232', \n",
    "    '78233', '78234', '78235', '78236', '78237', '78238', '78239', '78240', \n",
    "    '78242', '78244', '78245', '78247', '78248', '78249', '78250', '78251', \n",
    "    '78252', '78253', '78254', '78255', '78256', '78257', '78258', '78259', \n",
    "    '78260', '78261', '78263', '78264', '78266', '78269', '78270', '78278', \n",
    "    '78279', '78280', '78283', '78284', '78285', '78288', '78289', '78291', \n",
    "    '78292', '78293', '78294', '78295', '78296', '78297', '78298', '78299'\n",
    "}\n",
    "\n",
    "def detect_encoding(file_path, sample_size=10000):\n",
    "    \"\"\"Detect the encoding of a file by reading a sample\"\"\"\n",
    "    logger.info(f\"Detecting encoding for {file_path}\")\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        sample = file.read(sample_size)\n",
    "        result = chardet.detect(sample)\n",
    "        \n",
    "    logger.info(f\"Detected encoding: {result['encoding']} (confidence: {result['confidence']:.2f})\")\n",
    "    return result['encoding']\n",
    "\n",
    "def process_ppp_file(input_file, output_file, chunk_size=10000):\n",
    "    bexar_loans = []\n",
    "    total_processed = 0\n",
    "    bexar_found = 0\n",
    "    \n",
    "    logger.info(f\"Starting processing of {input_file}\")\n",
    "    logger.info(f\"Using {len(bexar_zips)} Bexar County ZIP codes for filtering\")\n",
    "    \n",
    "    # Detect encoding first\n",
    "    try:\n",
    "        encoding = detect_encoding(input_file)\n",
    "        if not encoding:\n",
    "            logger.warning(\"Could not detect encoding, trying common encodings...\")\n",
    "            encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "        else:\n",
    "            encodings_to_try = [encoding, 'utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error detecting encoding: {e}, trying common encodings...\")\n",
    "        encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "    \n",
    "    # Try different encodings\n",
    "    successful_encoding = None\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            logger.info(f\"Trying encoding: {encoding}\")\n",
    "            # Test read first few rows\n",
    "            test_chunk = pd.read_csv(input_file, encoding=encoding, nrows=5)\n",
    "            successful_encoding = encoding\n",
    "            logger.info(f\"Successfully opened file with encoding: {encoding}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed with encoding {encoding}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not successful_encoding:\n",
    "        logger.error(\"Could not open file with any encoding\")\n",
    "        return False\n",
    "    \n",
    "    # Now process the file with the successful encoding\n",
    "    try:\n",
    "        chunk_reader = pd.read_csv(input_file, encoding=successful_encoding, chunksize=chunk_size)\n",
    "        \n",
    "        for chunk_num, chunk in enumerate(chunk_reader):\n",
    "            # Log progress\n",
    "            total_processed += len(chunk)\n",
    "            logger.info(f\"Processing chunk {chunk_num + 1}, rows processed so far: {total_processed}\")\n",
    "            \n",
    "            # Check column names in first chunk\n",
    "            if chunk_num == 0:\n",
    "                logger.info(f\"Column names: {list(chunk.columns)}\")\n",
    "                # Try to identify the state and zip columns\n",
    "                state_cols = [col for col in chunk.columns if 'state' in col.lower() or 'st' in col.lower()]\n",
    "                zip_cols = [col for col in chunk.columns if 'zip' in col.lower() or 'postal' in col.lower()]\n",
    "                logger.info(f\"Potential state columns: {state_cols}\")\n",
    "                logger.info(f\"Potential zip columns: {zip_cols}\")\n",
    "            \n",
    "            # Filter for Texas first (adjust column name as needed)\n",
    "            # Common column names: BorrowerState, State, ST, etc.\n",
    "            state_column = None\n",
    "            zip_column = None\n",
    "            \n",
    "            for col in chunk.columns:\n",
    "                if 'state' in col.lower():\n",
    "                    state_column = col\n",
    "                if 'zip' in col.lower():\n",
    "                    zip_column = col\n",
    "            \n",
    "            if not state_column or not zip_column:\n",
    "                logger.error(f\"Could not find state or zip columns. Available columns: {list(chunk.columns)}\")\n",
    "                return False\n",
    "            \n",
    "            logger.info(f\"Using state column: {state_column}, zip column: {zip_column}\")\n",
    "            \n",
    "            tx_chunk = chunk[chunk[state_column].astype(str).str.upper() == 'TX']\n",
    "            logger.info(f\"Chunk {chunk_num + 1}: {len(tx_chunk)} TX loans out of {len(chunk)} total\")\n",
    "            \n",
    "            if not tx_chunk.empty:\n",
    "                # Filter by Bexar County ZIP codes\n",
    "                tx_chunk = tx_chunk.copy()\n",
    "                tx_chunk['zip_clean'] = tx_chunk[zip_column].astype(str).str.split('-').str[0].str.zfill(5)\n",
    "                bexar_chunk = tx_chunk[tx_chunk['zip_clean'].isin(bexar_zips)]\n",
    "                \n",
    "                if not bexar_chunk.empty:\n",
    "                    chunk_bexar_count = len(bexar_chunk)\n",
    "                    bexar_found += chunk_bexar_count\n",
    "                    logger.info(f\"Chunk {chunk_num + 1}: Found {chunk_bexar_count} Bexar County loans\")\n",
    "                    \n",
    "                    # Drop the temporary column before saving\n",
    "                    bexar_chunk = bexar_chunk.drop('zip_clean', axis=1)\n",
    "                    bexar_loans.append(bexar_chunk)\n",
    "                else:\n",
    "                    logger.info(f\"Chunk {chunk_num + 1}: No Bexar County loans found\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing file: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "    # Combine and save results\n",
    "    if bexar_loans:\n",
    "        logger.info(f\"Combining {len(bexar_loans)} chunks with Bexar County data\")\n",
    "        result = pd.concat(bexar_loans, ignore_index=True)\n",
    "        result.to_csv(output_file, index=False)\n",
    "        \n",
    "        logger.info(f\"SUMMARY:\")\n",
    "        logger.info(f\"Total rows processed: {total_processed}\")\n",
    "        logger.info(f\"Total Bexar County loans found: {len(result)}\")\n",
    "        logger.info(f\"Results saved to: {output_file}\")\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        logger.warning(\"No Bexar County loans found in the entire file\")\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"./sba_csv/public_150k_plus_240930.csv\"\n",
    "    output_file = \"bexar_county_ppp_150k_plus_loans.csv\"\n",
    "    \n",
    "    success = process_ppp_file(input_file, output_file)\n",
    "    if success:\n",
    "        print(\"Processing completed successfully!\")\n",
    "    else:\n",
    "        print(\"Processing failed or no results found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9a7ab-f9a9-4eec-923e-d7af98787c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alt SBA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d3c37-663c-498f-8451-fb0b23f05814",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bcd0fe-192b-4426-9945-2f23f126e0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
